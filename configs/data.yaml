# =========================
# DATA & TASK
# =========================
train_path: data/raw/train.csv
test_path: data/raw/test.csv
target_column: Survived
id_column: PassengerId
task_type: binary

required_columns:
  - PassengerId
  - Survived
  - Pclass
  - Name
  - Sex
  - Age
  - SibSp
  - Parch
  - Ticket
  - Fare
  - Cabin
  - Embarked

# What we want the model to treat as numeric/categorical (post-FE)
numeric_columns: [Age, SibSp, Parch, Fare, Ticket_number, TicketGroupSize, FamilySize]
categorical_columns: [Sex, Embarked, Pclass, Deck, Title, Ticket_prefix, IsAlone, AgeBin]

# =========================
# GLOBAL SWITCHES
# =========================
handle_missing: true
encode_categorical: true
scale_features: true
feature_importance: true

# Include original raw columns in final dataset (alongside engineered/encoded)
add_original_columns: false

# Explicit feature list used for training and prediction
train_columns:
  - AgeBin
  - FamilySize
  - IsAlone
  - TicketGroupSize
  - Ticket_number

# Only keep the ID as passthrough
skip_encoding_columns: [PassengerId]

# Params used by transforms
log_transform_fare: false
age_bins: 5
rare_title_threshold: null
# Optional explicit overrides for title normalization
title_map_override:
  Lady: Rare
  Countess: Rare
  Capt: Rare
  Col: Rare
  Don: Rare
  Dr: Rare
  Major: Rare
  Rev: Rare
  Sir: Rare
  Jonkheer: Rare
  Mlle: Miss
  Ms: Miss
  Mme: Mrs

# =========================
# ENCODING
# =========================
encoding:
  default:
    method: onehot
    handle_missing: "value"
    handle_unknown: "ignore"
  per_column:
    Title:
      method: onehot            # simple, no extra dependency
    Deck:
      method: ordinal           # safe, low-cardinality one-hot
    Embarked:
      method: onehot           # S/C/Q one-hot (clearer than single WOE col)
    AgeBin:
      method: ordinal          # treat as ordered categories

# =========================
# IMPUTATION
# =========================
imputation:
  # Fill Fare first, then predict Age using Fare + other features
  order: [Fare, Age]

  # Skip ID/text/engineered categoricals; we don't need to fill them
  exclude: [PassengerId, Name, Ticket, Title, Deck, Surname, Title_First_Middle, Title_Raw, First_Middle, MaidenName, Ticket_prefix]

  default:
    numeric: mean
    categorical: constant
    fill_value: "Unknown"
    add_missing_indicators: false
    missing_indicator_prefix: "__miss_"
    debug: true

  per_column:
#    Age:
#      method: model
#      estimator: random_forest
#      features: [Pclass, Sex, SibSp, Parch, Fare, Embarked]
#      n_estimators: 400
#      max_depth: null
#      random_state: 42
#      clip_min: 0
#      clip_max: 80
#
#    Fare:
#      method: mean
#      clip_min: 0

    Embarked:
      method: constant
      fill_value: "S"

    Cabin:
      method: most_frequent

# =========================
# FEATURE ENGINEERING STAGES (order matters)
# =========================
feature_engineering:
  pre_impute:
    - TitleTransform           # → Title + name-derived fields
    - FamilySizeTransform      # → FamilySize, IsAlone
    - TicketParseTransform     # → Ticket_prefix, Ticket_number
    - DeckTransform            # → Deck (maps missing to 'U')
    - TicketGroupTransform     # → TicketGroupSize (numeric)
  post_impute:
    - FareTransform            # fix Fare==0 using class mean  then optional log to Fare_log
    - AgeBinningTransform      # → AgeBin (numeric)

# Enable/disable individual transforms by class name
feature_toggles:
  TitleTransform: true
  FamilySizeTransform: true
  TicketParseTransform: true
  DeckTransform: true
  TicketGroupTransform: true
  FareTransform: true
  AgeBinningTransform: true

 # =========================
# FEATURE IMPORTANCE
# =========================
feature_importance_config:
  enabled: true
  algorithms: ["random_forest", "xgboost", "permutation"]  # Based on models.yaml algorithms
  output_dir: "artifacts/feature_importance"
  top_k_features: 20
  plot_importance: true
  save_results: true
  cross_validate: true
  cv_folds: 5
  random_state: 42

  # Algorithm-specific parameters
  algorithm_params:
    random_forest:
      n_estimators: 100
      max_depth: 10
      random_state: 42
    xgboost:
      n_estimators: 100
      max_depth: 4
      learning_rate: 0.1
      random_state: 42
    permutation:
      n_repeats: 10
      random_state: 42
      scoring: "accuracy"
