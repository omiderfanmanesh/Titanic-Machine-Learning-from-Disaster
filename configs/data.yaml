# =========================
# DATA & TASK
# =========================
train_path: data/raw/train.csv
test_path: data/raw/test.csv
target_column: Survived
id_column: PassengerId
task_type: binary

required_columns:
  - PassengerId
  - Survived
  - Pclass
  - Name
  - Sex
  - Age
  - SibSp
  - Parch
  - Ticket
  - Fare
  - Cabin
  - Embarked

# What we want the model to treat as numeric/categorical (post-FE)
numeric_columns: [Age, SibSp, Parch, Fare, Ticket_number, TicketGroupSize, FamilySize]
categorical_columns: [Sex,Surname, Embarked, Pclass, Deck, Title,Ticket_number, Ticket_prefix, IsAlone, AgeBin]

# =========================
# GLOBAL SWITCHES
# =========================
handle_missing: true
encode_categorical: true
scale_features: true
feature_importance: false

# =========================
# DIMENSIONALITY REDUCTION (optional)
# =========================
dimensionality_reduction:
  enabled: false          # Set true to enable (applies after scaling)
  method: pca             # pca | svd
  n_components: null         # int; or null with keep_variance for PCA
  keep_variance: 0.95     # e.g., 0.95 to keep 95% variance (PCA only)
  whiten: false           # PCA whitening
  random_state: 42

# =========================
# CROSS-VALIDATION & TRAINING (optional)
# When provided here, these override experiment.yaml for convenience.
# =========================
cv_strategy: stratified       # stratified (default), group, kfold, timeseries
cv_folds: 2
cv_shuffle: true
cv_random_state: 42
cv_metric: f1                 # accuracy, f1, or roc_auc
# group_column: FamilyID      # only if using cv_strategy: group and you have this column in RAW data

# Include original raw columns in final dataset (alongside engineered/encoded)
add_original_columns: false

# =========================
# IMBALANCE HANDLING (optional)
# =========================
# Simple binary-class balancing on the training split per fold.
# enabled: true|false, method: downsample|upsample
imbalance:
  enabled: false
  # strategy: downsample|upsample|random_under|random_over|smote|adasyn
  strategy: downsample
  # Optional extra parameters passed to imblearn samplers (if used)
  # params:
  #   sampling_strategy: auto
  #   k_neighbors: 5

# =========================
# CLASS WEIGHTING (optional)
# =========================
# Alternative to resampling. If both imbalance.enabled and class_weight.enabled
# are true, resampling is applied first, then class_weight/sample_weight.
class_weight:
  enabled: true
  # scheme: balanced|custom
  scheme: balanced
  # Only used when scheme: custom
  # weights: {0: 1.0, 1: 2.0}

# Explicit feature list (optional). If provided, list PRE-ENCODING names
# (e.g., Pclass, Sex, Embarked, Title, Age, Fare). The pipeline will include
# those numeric columns directly and all encoded outputs derived from
# categorical names (e.g., Pclass_*). If omitted, the exclusion list below applies.
# train_columns: []

# Columns to drop from training/prediction if train_columns is not specified
exclude_column_for_training:
  - Cabin
  - Ticket_number
  - First_Middle
  - MaidenName
  - Surname
  - Ticket_prefix
  - Title_First_Middle
  - Title_Raw
  - IsAlone
  - Age
  - TicketGroupSize
  - Deck
  - Embarked
#  - Pclass
#  - Sex
#  - Title
#  - Parch
#  - SibSp
#  - FamilySize




# Only keep the ID as passthrough
skip_encoding_columns: [PassengerId]

# Params used by transforms
log_transform_fare: true
age_bins: 5
rare_title_threshold: null
# Optional explicit overrides for title normalization
title_map_override:
  Lady: Rare
  Countess: Rare
  Capt: Rare
  Col: Rare
  Don: Rare
  Dr: Rare
  Major: Rare
  Rev: Rare
  Sir: Rare
  Jonkheer: Rare
  Mlle: Miss
  Ms: Miss
  Mme: Mrs

# =========================
# ENCODING
# =========================
encoding:
  default:
    method: onehot
    handle_missing: "value"
    handle_unknown: "ignore"
  per_column:
#    Surname:
#      method: onehot       # keep as-is, no encoding
    Title:
      method: onehot            # simple, no extra dependency
    Deck:
      method: onehot           # safe, low-cardinality one-hot
    Embarked:
      method: onehot           # S/C/Q one-hot (clearer than single WOE col)
    AgeBin:
      method: onehot          # treat as ordered categories
#    Ticket_number:
#      method: label           # keep as-is, no encoding
#    Ticket_prefix:
#      method: label           # keep as-is, no encoding

# =========================
# IMPUTATION
# =========================
imputation:
  # Impute in order: Fare -> Embarked -> Age
  order: [ Embarked,Age]

  # Skip ID/text/engineered categoricals; we don't need to fill them
  exclude: [PassengerId, Name,  Title, Deck, Surname, Title_First_Middle, Title_Raw, First_Middle, MaidenName]

  default:
    numeric: mean
    categorical: constant
    fill_value: "Unknown"
    add_missing_indicators: false
    missing_indicator_prefix: "__miss_"
    debug: true

  per_column:
#    Age:
#      method: mean
#    Age:
#      method: model
#      estimator: random_forest
#      features: [Pclass, Sex, SibSp, Parch, Fare, Embarked]
#      n_estimators: 400
#      max_depth: null
#      random_state: 42
#      clip_min: 0
#      clip_max: 80

#    Fare:
#      method: mean
#      clip_min: 0

    Embarked:
      method: constant
      fill_value: "S"
    Ticket_number:
      method: most_frequent
    Ticket_prefix:
      method: most_frequent

    Cabin:
      method: most_frequent

# =========================
# FEATURE ENGINEERING STAGES (order matters)
# =========================
feature_engineering:
  pre_impute:
    - TitleTransform           # → Title + name-derived fields
    - FamilySizeTransform      # → FamilySize, IsAlone
    - TicketParseTransform     # → Ticket_prefix, Ticket_number (before imputation)
    - DeckTransform            # → Deck (maps missing to 'U')
    - AgeImputeByTitleTransform # Impute Age using Title + Pclass (before Fare imputation)
  post_impute:
    - TicketGroupTransform     # → TicketGroupSize (numeric)
    - FareTransform            # fix Fare==0 using class mean  then optional log to Fare_log
    - AgeBinningTransform      # → AgeBin (numeric)

# Enable/disable individual transforms by class name
feature_toggles:
  TitleTransform: true
  FamilySizeTransform: true
  TicketParseTransform: true
  DeckTransform: true
  TicketGroupTransform: True
  FareTransform: true
  AgeBinningTransform: true
  AgeImputeByTitleTransform: false  # Impute Age using Title + Pclass

 # =========================
# FEATURE IMPORTANCE
# =========================
feature_importance_config:
  enabled: true
  algorithms: ["random_forest", "xgboost", "permutation"]  # Based on models.yaml algorithms
  output_dir: "artifacts/feature_importance"
  top_k_features: 20
  plot_importance: true
  save_results: true
  cross_validate: true
  cv_folds: 2
  random_state: 42

  # Algorithm-specific parameters
  algorithm_params:
    random_forest:
      n_estimators: 100
      max_depth: 10
      random_state: 42
    xgboost:
      n_estimators: 100
      max_depth: 4
      learning_rate: 0.1
      random_state: 42
    permutation:
      n_repeats: 10
      random_state: 42
      scoring: "roc_auc"  # or "accuracy", "roc_auc", etc.
